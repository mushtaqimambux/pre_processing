{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5cb3ac64-3713-4e9a-a118-2dfe26136386",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "<h1>?sooo yesterday!!!</h1> i taught       the <b>students</b> about <i>nlp preprocessing</i> , yeah yeah like lower  CASE , stop words, and punctuation ... oh wow!! what a  mess mess... there were about 21 or 22 students 999 888 maybe ?? not sure ğŸ¤” anyway  we talked and talked  and talked about commas, dots, dots... more dots..... ??? question marks, semi;colons;;; and other stuff !!!!  \n",
    "then some <div> of </div> them said like â€œsir why we remove punctuation 123 456 789 numbers , html tags <p></p> and spaces spaces   and more  spaces ???â€ i said because it makes <code>the data clean clean clean</code> oh yes YES yes.  \n",
    "we also found sooo many stopwords like \"the\" \"a\" \"an\" \"is\" \"of\" \"in\" \"to\" \"on\" \"for\" <span>and</span>  \"that\" \"by\" oh nooo, and ugh  repeated words everywhere everywhere everywhere !!!  \n",
    "sometimes  the  text  had  BIG  letters, small letters, Missing letters, ...  punctuation,  punctuation,  punctuation!!!  ğŸ˜©ğŸ˜© lowercase is important, uppercase looks  BAD BAD BAD!!!  \n",
    "and  we  found  multiple   spaces     like     this     one     and    even     worse    ones.   some sentences ended ??? without any reason ... others ended !!!!!!! or ........ or 1234567890 randomly inserted in middle of text ğŸ˜ .  \n",
    "students were like <a href=\"#\">sir we tired</a> ğŸ˜´ but i said â€œno!! clean the DATA!! remove html tags <img> <body> <head>, remove punctuation!!!!! remove stopwords, remove numbers 000111222333, remove emojis ğŸ˜…ğŸ˜‚ğŸ, remove extra spaces!!! â€  \n",
    "then one student wrote: REMOVE   STOPWORDS  PLEASE!!!!!! PLEASE  PLEASE!!!! in ALL CAPS ğŸ˜­ğŸ˜­ğŸ˜­ and forgot half of the text lol lol lol.  \n",
    "we used nltk , regex , and re.sub() and .split() and join() join() join()  functions ... oh so many ( ) ( ) [ ] { } symbols; ; ; ; !!!  \n",
    "btw <html> we </html> also found that lowercase makes the <p>text</p> more readable readable readable readable readable !!! not LIKE THIS or LIKE THAT .  \n",
    "<article> after </article> finishing <section> class </section> , we all laughed, smiled, cleaned cleaned data, removed numbers(12345 67890), stopwords stopwords stopwords stopwords, and extra  spaces!!!  \n",
    "finally the dataset looked better better better better, before it was a big mess mess mess mess mess full of tags <div> <meta> <h1> </h1> <title> broken html <br> <hr> </hr> punctuation!!!  \n",
    "some text was like:  <b>this.. is.. just.. messy.. text..!!!</b>  others like  what??? why???? no idea... anyway.  \n",
    "cleaning text is so boring boring boring but also fun fun fun!!! it makes model smarter, faster, better, clearer, not slower slower slower ğŸ˜œğŸ˜œğŸ˜œ.  \n",
    "and i said again again again, â€œdonâ€™t forget to remove punctuation, stopwords, numbers, emojis, and html tags!!!â€  \n",
    "then they all said â€œyes sir yes sirâ€ three times three times three times.  \n",
    "<footer> and </footer> thatâ€™s how preprocessing works works works â€” lower, clean, trim, remove, filter, normalize normalize normalize normalize!!!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1804c553-6c93-4853-be84-49e59600ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7b8682aa-7e35-454f-b8c8-1cbbd6d9cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove HTML Tags\n",
    "text = re.sub(r'<.*?>', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9273dc1d-b538-472a-b00b-65a242042035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change case to lowercase\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dec8babd-201a-489a-8bfa-39f8f33078a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers\n",
    "text = re.sub(r'\\d+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "18ca3b82-6a5b-48fc-8bf0-7724e5b32bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get list of punctuations\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7e90eb4d-9407-4604-8c02-0ce49d6acb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Punctuations\n",
    "text = \"\".join([m for m in text if m not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3af86d23-a652-46bc-818b-920d5600938e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sooo yesterday i taught       the students about nlp preprocessing  yeah yeah like lower  case  stop words and punctuation  oh wow what a  mess mess there were about  or  students   maybe  not sure ğŸ¤” anyway  we talked and talked  and talked about commas dots dots more dots  question marks semicolons and other stuff   \\nthen some  of  them said like â€œsir why we remove punctuation    numbers  html tags  and spaces spaces   and more  spaces â€ i said because it makes the data clean clean clean oh yes yes yes  \\nwe also found sooo many stopwords like the a an is of in to on for and  that by oh nooo and ugh  repeated words everywhere everywhere everywhere   \\nsometimes  the  text  had  big  letters small letters missing letters   punctuation  punctuation  punctuation  ğŸ˜©ğŸ˜© lowercase is important uppercase looks  bad bad bad  \\nand  we  found  multiple   spaces     like     this     one     and    even     worse    ones   some sentences ended  without any reason  others ended  or  or  randomly inserted in middle of text ğŸ˜   \\nstudents were like sir we tired ğŸ˜´ but i said â€œno clean the data remove html tags    remove punctuation remove stopwords remove numbers  remove emojis ğŸ˜…ğŸ˜‚ğŸ remove extra spaces â€  \\nthen one student wrote remove   stopwords  please please  please in all caps ğŸ˜­ğŸ˜­ğŸ˜­ and forgot half of the text lol lol lol  \\nwe used nltk  regex  and resub and split and join join join  functions  oh so many         symbols      \\nbtw  we  also found that lowercase makes the text more readable readable readable readable readable  not like this or like that   \\n after  finishing  class   we all laughed smiled cleaned cleaned data removed numbers  stopwords stopwords stopwords stopwords and extra  spaces  \\nfinally the dataset looked better better better better before it was a big mess mess mess mess mess full of tags      broken html    punctuation  \\nsome text was like  this is just messy text  others like  what why no idea anyway  \\ncleaning text is so boring boring boring but also fun fun fun it makes model smarter faster better clearer not slower slower slower ğŸ˜œğŸ˜œğŸ˜œ  \\nand i said again again again â€œdonâ€™t forget to remove punctuation stopwords numbers emojis and html tagsâ€  \\nthen they all said â€œyes sir yes sirâ€ three times three times three times  \\n and  thatâ€™s how preprocessing works works works â€” lower clean trim remove filter normalize normalize normalize normalize'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove extra spaces from start and end of words, new line characters, tab characters\n",
    "text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c0c4c034-b16b-4a65-ac53-3a8be5a1fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "text = re.sub(r'\\s+', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cca9487e-0f54-4269-a619-ccc208473b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sooo yesterday i taught the students about nlp preprocessing yeah yeah like lower case stop words and punctuation oh wow what a mess mess there were about or students maybe not sure ğŸ¤” anyway we talked and talked and talked about commas dots dots more dots question marks semicolons and other stuff then some of them said like â€œsir why we remove punctuation numbers html tags and spaces spaces and more spaces â€ i said because it makes the data clean clean clean oh yes yes yes we also found sooo many stopwords like the a an is of in to on for and that by oh nooo and ugh repeated words everywhere everywhere everywhere sometimes the text had big letters small letters missing letters punctuation punctuation punctuation ğŸ˜©ğŸ˜© lowercase is important uppercase looks bad bad bad and we found multiple spaces like this one and even worse ones some sentences ended without any reason others ended or or randomly inserted in middle of text ğŸ˜ students were like sir we tired ğŸ˜´ but i said â€œno clean the data remove html tags remove punctuation remove stopwords remove numbers remove emojis ğŸ˜…ğŸ˜‚ğŸ remove extra spaces â€ then one student wrote remove stopwords please please please in all caps ğŸ˜­ğŸ˜­ğŸ˜­ and forgot half of the text lol lol lol we used nltk regex and resub and split and join join join functions oh so many symbols btw we also found that lowercase makes the text more readable readable readable readable readable not like this or like that after finishing class we all laughed smiled cleaned cleaned data removed numbers stopwords stopwords stopwords stopwords and extra spaces finally the dataset looked better better better better before it was a big mess mess mess mess mess full of tags broken html punctuation some text was like this is just messy text others like what why no idea anyway cleaning text is so boring boring boring but also fun fun fun it makes model smarter faster better clearer not slower slower slower ğŸ˜œğŸ˜œğŸ˜œ and i said again again again â€œdonâ€™t forget to remove punctuation stopwords numbers emojis and html tagsâ€ then they all said â€œyes sir yes sirâ€ three times three times three times and thatâ€™s how preprocessing works works works â€” lower clean trim remove filter normalize normalize normalize normalize'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5f3e6575-66c1-46f9-a9cf-f6c08ffbcf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mushtaq\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0d61d786-0c60-4de5-9c83-93294dc99085",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eecc4230-7fd8-4958-acc2-301c92e92fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join([word for word in text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4ea86567-79b5-40bf-a7b0-94c2f90a255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'[^a-zA-Z0-9\\s\\x22\\x27\\u201c\\u201d]', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "efbfa6ab-107f-4b0b-ad18-127d4ea19052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sooo yesterday taught students nlp preprocessing yeah yeah like lower case stop words punctuation oh wow mess mess students maybe sure  anyway talked talked talked commas dots dots dots question marks semicolons stuff said like â€œsir remove punctuation numbers html tags spaces spaces spaces â€ said makes data clean clean clean oh yes yes yes also found sooo many stopwords like oh nooo ugh repeated words everywhere everywhere everywhere sometimes text big letters small letters missing letters punctuation punctuation punctuation  lowercase important uppercase looks bad bad bad found multiple spaces like one even worse ones sentences ended without reason others ended randomly inserted middle text  students like sir tired  said â€œno clean data remove html tags remove punctuation remove stopwords remove numbers remove emojis  remove extra spaces â€ one student wrote remove stopwords please please please caps  forgot half text lol lol lol used nltk regex resub split join join join functions oh many symbols btw also found lowercase makes text readable readable readable readable readable like like finishing class laughed smiled cleaned cleaned data removed numbers stopwords stopwords stopwords stopwords extra spaces finally dataset looked better better better better big mess mess mess mess mess full tags broken html punctuation text like messy text others like idea anyway cleaning text boring boring boring also fun fun fun makes model smarter faster better clearer slower slower slower  said â€œdont forget remove punctuation stopwords numbers emojis html tagsâ€ said â€œyes sir yes sirâ€ three times three times three times thats preprocessing works works works  lower clean trim remove filter normalize normalize normalize normalize'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "570bb341-1319-4a06-82c6-763bb15dff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace(' â€','â€')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b214516f-7ed8-4b11-9dc4-e85080680b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sooo yesterday taught students nlp preprocessing yeah yeah like lower case stop words punctuation oh wow mess mess students maybe sure  anyway talked talked talked commas dots dots dots question marks semicolons stuff said like â€œsir remove punctuation numbers html tags spaces spaces spacesâ€ said makes data clean clean clean oh yes yes yes also found sooo many stopwords like oh nooo ugh repeated words everywhere everywhere everywhere sometimes text big letters small letters missing letters punctuation punctuation punctuation  lowercase important uppercase looks bad bad bad found multiple spaces like one even worse ones sentences ended without reason others ended randomly inserted middle text  students like sir tired  said â€œno clean data remove html tags remove punctuation remove stopwords remove numbers remove emojis  remove extra spacesâ€ one student wrote remove stopwords please please please caps  forgot half text lol lol lol used nltk regex resub split join join join functions oh many symbols btw also found lowercase makes text readable readable readable readable readable like like finishing class laughed smiled cleaned cleaned data removed numbers stopwords stopwords stopwords stopwords extra spaces finally dataset looked better better better better big mess mess mess mess mess full tags broken html punctuation text like messy text others like idea anyway cleaning text boring boring boring also fun fun fun makes model smarter faster better clearer slower slower slower  said â€œdont forget remove punctuation stopwords numbers emojis html tagsâ€ said â€œyes sir yes sirâ€ three times three times three times thats preprocessing works works works  lower clean trim remove filter normalize normalize normalize normalize'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc84ec-0479-424e-9898-ab70c3515fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
